{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# DATA_FOLDER = \"./whole_array/sweep_runs/run4/results\"\n",
    "DATA_FOLDER = \"./whole_array/sweep_runs/run5_24_06_25/results\"\n",
    "\n",
    "INPUT_COLS = [\"M\", \"K\", \"N\"]\n",
    "OUTPUT_COL = \"It1\"  # Execution time\n",
    "hardware = \"strix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(filename):\n",
    "    \"\"\"\n",
    "    Parses a filename to extract hardware ID and hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The base name of the file (e.g., \"32x32x32_4x8x4_bf16_out_8_col_peano.csv\")\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with 'hardware_id' and other hyperparameter keys.\n",
    "              Returns None if parsing fails.\n",
    "    \"\"\"\n",
    "    parts = filename.replace(\".csv\", \"\").split(\"_\")\n",
    "    params = {}\n",
    "    if len(parts) == 7:\n",
    "        params[\"mkn\"] = parts[0]\n",
    "        params[\"rst\"] = parts[1]\n",
    "        params[\"out\"] = parts[2]\n",
    "        params[\"cols\"] = parts[4]\n",
    "        params[\"compiler\"] = parts[6]\n",
    "    else:\n",
    "        print(\n",
    "            f\"Failed to parse filename '{filename}': Expected 7 parts, got {len(parts)}\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    # param_items = sorted([f\"{k}-{v}\" for k, v in params.items()])\n",
    "    param_items = [f\"{v}\" for _, v in params.items()]\n",
    "    params[\"hyperparameter_set\"] = (\n",
    "        \"_\".join(param_items)\n",
    "        if param_items\n",
    "        else params.get(\"config_name\", \"unknown_config\")\n",
    "    )\n",
    "    params[\"hardware_id\"] = \"strix\"\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load and Combine Data ---\n",
    "all_data = []\n",
    "csv_files = glob.glob(os.path.join(DATA_FOLDER, \"*.csv\"))\n",
    "\n",
    "if not csv_files:\n",
    "    print(f\"No CSV files found in '{DATA_FOLDER}'. Please check the path.\")\n",
    "else:\n",
    "    print(f\"Found {len(csv_files)} CSV files. Loading...\")\n",
    "    for f_path in csv_files:\n",
    "        try:\n",
    "            df_temp = pd.read_csv(f_path)\n",
    "            base_filename = os.path.basename(f_path)\n",
    "\n",
    "            # Extract parameters from filename\n",
    "            file_params = parse_filename(base_filename)\n",
    "            if file_params:\n",
    "                for key, value in file_params.items():\n",
    "                    df_temp[key] = value\n",
    "                all_data.append(df_temp)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Warning: Could not parse parameters from filename: {base_filename}\"\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading or processing file {f_path}: {e}\")\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"No data loaded. Exiting.\")\n",
    "        master_df = pd.DataFrame()\n",
    "    else:\n",
    "        master_df = pd.concat(all_data, ignore_index=True)\n",
    "        print(\"\\n--- Combined Data Head ---\")\n",
    "        print(master_df.head())\n",
    "        print(\"\\n--- Combined Data Info ---\")\n",
    "        master_df.info()\n",
    "\n",
    "        # Ensure output is numeric\n",
    "        master_df[OUTPUT_COL] = pd.to_numeric(master_df[OUTPUT_COL], errors=\"coerce\")\n",
    "        master_df_nans = master_df.copy()\n",
    "        master_df.dropna(subset=[OUTPUT_COL], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "The following cell contains various plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions\n",
    "def hyperparameter_comparison_for_sampled_column(\n",
    "    df: pd.DataFrame, y_col: str, hardware: str, sampled_column: str = \"input_shape_id\"\n",
    "):\n",
    "    if not df[sampled_column].empty:\n",
    "        sample_input_shape = df[sampled_column].sample(1).iloc[0]\n",
    "        print(f\"\\n--- Performance for Input Shape: {sample_input_shape} ---\")\n",
    "\n",
    "        df_specific_shape = df[df[sampled_column] == sample_input_shape]\n",
    "\n",
    "        if not df_specific_shape.empty:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.barplot(data=df_specific_shape, x=\"hyperparameter_set\", y=y_col)\n",
    "            plt.title(\n",
    "                f\"{y_col} for {sampled_column}: {sample_input_shape} (Hardware: {hardware})\"\n",
    "            )\n",
    "            plt.xlabel(\"Hyperparameter Set\")\n",
    "            plt.ylabel(f\"{y_col}\")\n",
    "            plt.xticks(rotation=45, ha=\"right\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"No data for sample input shape {sample_input_shape} to plot.\")\n",
    "\n",
    "\n",
    "def distribution_analysis_box_plot(df: pd.DataFrame, y_col: str, hardware: str):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.boxplot(data=df, x=\"hyperparameter_set\", y=y_col, whis=100)\n",
    "    plt.title(f\"Overall {y_col} Distribution (Hardware: {hardware})\")\n",
    "    plt.xlabel(\"Hyperparameter Set\")\n",
    "    plt.ylabel(f\"{y_col}\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def classic_line_plot(df: pd.DataFrame, x_col: str, y_col: str, hardware: str):\n",
    "    if x_col in df.columns:\n",
    "        df_sorted = df.sort_values(by=x_col, inplace=False)\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        # This could also be replaced by a scatter plot if you want to show individual points\n",
    "        sns.lineplot(\n",
    "            data=df_sorted,\n",
    "            x=x_col,\n",
    "            y=y_col,\n",
    "            hue=\"hyperparameter_set\",\n",
    "            alpha=0.7,\n",
    "            # s=50,\n",
    "        )\n",
    "        plt.title(f\"{x_col} vs. {y_col} (Hardware: {hardware})\")\n",
    "        plt.xlabel(x_col)\n",
    "        plt.ylabel(y_col)\n",
    "        plt.legend(\n",
    "            title=\"Hyperparameter Set\", bbox_to_anchor=(1.05, 1), loc=\"upper left\"\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def winner_on_grouped_column(\n",
    "    df: pd.DataFrame,\n",
    "    x_col: str,\n",
    "    y_col: str,\n",
    "    hardware: str,\n",
    "    grouped_column: str = \"input_shape_id\",\n",
    "):\n",
    "    # Identify \"Best\" Hyperparameter Set for Each Input Shape\n",
    "    print(\"\\n--- Identifying Best Hyperparameter Set per Input Shape ---\")\n",
    "    # Find the row with the minimum output time for each grouped_column\n",
    "    best_performers = df.loc[df.groupby(grouped_column)[y_col].idxmin()]\n",
    "\n",
    "    print(best_performers[[grouped_column, \"hyperparameter_set\", y_col]].head())\n",
    "\n",
    "    # Which hyperparameter set wins most often?\n",
    "    if not best_performers.empty:\n",
    "        print(\"\\n--- Count of 'Wins' per Hyperparameter Set ---\")\n",
    "        win_counts = best_performers[\"hyperparameter_set\"].value_counts()\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        win_counts.plot(kind=\"bar\")\n",
    "        plt.title(\n",
    "            f\"Number of Times Each Hyperparameter Set Was Fastest (Hardware: {hardware})\"\n",
    "        )\n",
    "        plt.xlabel(\"Hyperparameter Set\")\n",
    "        plt.ylabel(\"Number of Input Shapes Won\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(win_counts)\n",
    "    else:\n",
    "        print(\"No best performers found to summarize wins.\")\n",
    "\n",
    "\n",
    "def average_performance_rank(\n",
    "    df: pd.DataFrame, y_col: str, hardware: str, grouped_column: str = \"input_shape_id\"\n",
    "):\n",
    "    df[\"rank\"] = df.groupby(\"input_shape_id\")[y_col].rank(method=\"min\")\n",
    "    avg_rank = df.groupby(\"hyperparameter_set\")[\"rank\"].mean().sort_values()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    avg_rank.plot(kind=\"bar\")\n",
    "    plt.title(f\"Average Performance Rank by Hyperparameter Set (Hardware: {hardware})\")\n",
    "    plt.xlabel(\"Hyperparameter Set\")\n",
    "    plt.ylabel(\"Average Rank (Lower is Better)\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(avg_rank)\n",
    "\n",
    "\n",
    "def scatter_plot_3d(\n",
    "    df: pd.DataFrame,\n",
    "    x_col: str,\n",
    "    y_col: str,\n",
    "    z_col: str,\n",
    "    hardware: str,\n",
    "):\n",
    "    try:\n",
    "        fig_3d = px.scatter_3d(\n",
    "            df,\n",
    "            x=x_col,\n",
    "            y=y_col,\n",
    "            z=z_col,\n",
    "            color=\"hyperparameter_set\",\n",
    "            # symbol='hyperparameter_set', # Can also use symbol\n",
    "            opacity=0.7,\n",
    "            title=f\"3D Performance: {x_col} & {y_col} vs. {z_col} (Hardware: {hardware})\",\n",
    "        )\n",
    "        # To make points smaller if there are many\n",
    "        # fig_3d.update_traces(marker=dict(size=3))\n",
    "        fig_3d.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate 3D plot: {e}\")\n",
    "\n",
    "\n",
    "def compare_compilers_for_identical_configs(\n",
    "    df: pd.DataFrame,\n",
    "    y_col: str,\n",
    "    hardware: str,\n",
    "    compiler_col: str,\n",
    "    base_config_col: str = \"hyperparameter_set\",\n",
    "    shape_id_col: str = \"input_shape_id\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Compares performance of different compilers when the rest of the hyperparameter set is identical,\n",
    "    for each input shape.\n",
    "    \"\"\"\n",
    "    unique_compilers = df[compiler_col].unique()\n",
    "    if len(unique_compilers) < 2:\n",
    "        print(f\"Not enough compilers to compare (found: {unique_compilers}). Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Pivot table to get compilers side-by-side for each base_config and input_shape\n",
    "    # We need to handle cases where a compiler might be missing for a specific config/shape\n",
    "    df_pivot = df.pivot_table(\n",
    "        index=[base_config_col, shape_id_col],\n",
    "        columns=compiler_col,\n",
    "        values=y_col,\n",
    "        aggfunc=\"mean\",\n",
    "    )  # Use mean if multiple entries for same compiler/config/shape\n",
    "\n",
    "    # Drop rows where not all compilers have data (or at least two for comparison)\n",
    "    df_pivot.dropna(\n",
    "        thresh=2, inplace=True\n",
    "    )  # Keep rows with at least 2 non-NaN compiler values\n",
    "\n",
    "    if df_pivot.empty:\n",
    "        print(\n",
    "            \"No input shapes found where multiple compilers ran with the same base hyperparameters.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Calculate relative performance or plot side-by-side\n",
    "    # For simplicity, let's pick two compilers if more are present, or plot all if just two\n",
    "    compilers_to_plot = df_pivot.columns.tolist()\n",
    "\n",
    "    if len(compilers_to_plot) >= 2:\n",
    "        # Option 1: Scatter plot comparing two compilers directly\n",
    "        # (More complex if >2 compilers, would need multiple plots or different viz)\n",
    "        # if len(compilers_to_plot) == 2:\n",
    "        #     c1, c2 = compilers_to_plot[0], compilers_to_plot[1]\n",
    "        #     plt.figure(figsize=(8, 8))\n",
    "        #     sns.scatterplot(\n",
    "        #         data=df_pivot,\n",
    "        #         x=c1,\n",
    "        #         y=c2,\n",
    "        #         hue=df_pivot.index.get_level_values(base_config_col),\n",
    "        #         s=50,\n",
    "        #         alpha=0.7,\n",
    "        #     )\n",
    "        #     min_val = min(df_pivot[c1].min(), df_pivot[c2].min())\n",
    "        #     max_val = max(df_pivot[c1].max(), df_pivot[c2].max())\n",
    "        #     plt.plot(\n",
    "        #         [min_val, max_val],\n",
    "        #         [min_val, max_val],\n",
    "        #         \"k--\",\n",
    "        #         lw=1,\n",
    "        #         label=\"y=x (Equal Performance)\",\n",
    "        #     )\n",
    "        #     plt.xlabel(f\"Execution Time ({c1})\")\n",
    "        #     plt.ylabel(f\"Execution Time ({c2})\")\n",
    "        #     plt.title(\n",
    "        #         f\"Compiler Performance: {c1} vs {c2} (Hardware: {hardware})\\n(Identical Base Configs & Input Shapes)\"\n",
    "        #     )\n",
    "        #     plt.legend(\n",
    "        #         title=\"Base Hyperparameter Set\",\n",
    "        #         bbox_to_anchor=(1.05, 1),\n",
    "        #         loc=\"upper left\",\n",
    "        #     )\n",
    "        #     plt.grid(True)\n",
    "        #     plt.tight_layout()\n",
    "            # plt.show()\n",
    "\n",
    "        # Option 2: Bar plot of average speedup/slowdown\n",
    "        # Or, for each base_config, show bar plots for a few input_shapes\n",
    "        # Let's do a summary: For each base_config, which compiler is better on average?\n",
    "\n",
    "        # Calculate mean performance for each compiler across shapes for each base_config\n",
    "        mean_perf_by_base_config = df_pivot.groupby(level=base_config_col).mean()\n",
    "\n",
    "        if not mean_perf_by_base_config.empty:\n",
    "            mean_perf_by_base_config.plot(kind=\"bar\", figsize=(12, 7))\n",
    "            plt.title(\n",
    "                f\"Average {y_col} by {compiler_col} for each Base Config (Hardware: {hardware})\"\n",
    "            )\n",
    "            plt.xlabel(\"Base Hyperparameter Set\")\n",
    "            plt.ylabel(f\"Average {y_col} (lower is better)\")\n",
    "            plt.xticks(rotation=45, ha=\"right\")\n",
    "            plt.legend(title=compiler_col)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Percentage difference (example for 2 compilers)\n",
    "            if len(compilers_to_plot) == 2:\n",
    "                c1, c2 = compilers_to_plot[0], compilers_to_plot[1]\n",
    "                # Positive means c2 is slower than c1 by X%\n",
    "                df_pivot[f\"{c2}_vs_{c1}_diff_pct\"] = (\n",
    "                    (df_pivot[c2] - df_pivot[c1]) / df_pivot[c1]\n",
    "                ) * 100\n",
    "\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                sns.histplot(df_pivot[f\"{c2}_vs_{c1}_diff_pct\"].dropna(), kde=True)\n",
    "                plt.title(\n",
    "                    f\"Distribution of Performance Difference: {c2} vs {c1}\\n(Hardware: {hardware}, Identical Base Configs)\"\n",
    "                )\n",
    "                plt.xlabel(f\"Percentage Difference in {y_col} ({c2} relative to {c1})\")\n",
    "                plt.ylabel(\"Frequency\")\n",
    "                plt.axvline(0, color=\"k\", linestyle=\"--\")\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                print(f\"A positive value indicates that {c2} is slower than {c1} by that percentage: Formula used: (({c2} - {c1}) / {c1}) * 100\")\n",
    "                \n",
    "                print(f\"\\nSummary of {c2} vs {c1} performance difference (%):\")\n",
    "                print(df_pivot[f\"{c2}_vs_{c1}_diff_pct\"].describe())\n",
    "\n",
    "                # Print information on outlier shapes\n",
    "                print(\"Configurations where the performance difference is highest:\")\n",
    "                print(df_pivot[f\"{c2}_vs_{c1}_diff_pct\"].idxmax())\n",
    "                print(\"Configurations where the performance difference is lowest:\")\n",
    "                print(df_pivot[f\"{c2}_vs_{c1}_diff_pct\"].idxmin())\n",
    "\n",
    "    else:\n",
    "        print(\"Could not find enough compiler data on pivot table for comparison.\")\n",
    "\n",
    "\n",
    "def plot_execution_time_vs_MxKxN(\n",
    "    df: pd.DataFrame,\n",
    "    y_col: str,\n",
    "    hardware: str,\n",
    "    MxKxN_col_name: str,\n",
    "    hyperparam_set_col: str = \"hyperparameter_set\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots how average execution time increases with matrix size for each hyperparameter set.\n",
    "    \"\"\"\n",
    "    if MxKxN_col_name not in df.columns:\n",
    "        print(f\"Error: Column '{MxKxN_col_name}' not found in DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # Calculate average execution time for each hyperparameter_set and MxKxN\n",
    "    # This handles multiple entries for the same matrix size and hyperparameter set\n",
    "    df_agg = (\n",
    "        df.groupby([hyperparam_set_col, MxKxN_col_name])[y_col]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Sort by matrix size for cleaner plotting\n",
    "    df_agg = df_agg.sort_values(by=MxKxN_col_name)\n",
    "\n",
    "    if df_agg.empty:\n",
    "        print(f\"No aggregated data to plot for time vs {MxKxN_col_name}.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    # Using lineplot to show trends\n",
    "    sns.lineplot(\n",
    "        data=df_agg,\n",
    "        x=MxKxN_col_name,\n",
    "        y=y_col,\n",
    "        hue=hyperparam_set_col,\n",
    "        marker=\"o\",\n",
    "        errorbar=None,\n",
    "    )\n",
    "    # If you didn't pre-aggregate with .mean(), seaborn's lineplot would show confidence intervals by default.\n",
    "    # sns.lineplot(data=df, x=MxKxN_col_name, y=y_col, hue=hyperparam_set_col, marker='o')\n",
    "\n",
    "    plt.title(\n",
    "        f\"Average {y_col} vs. {MxKxN_col_name} by Hyperparameter Set (Hardware: {hardware})\"\n",
    "    )\n",
    "    plt.xlabel(f\"{MxKxN_col_name}\")\n",
    "    plt.ylabel(f\"Average {y_col}\")\n",
    "    plt.legend(title=\"Hyperparameter Set\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.xscale(\"log\")  # Often matrix sizes grow exponentially, log scale can be useful\n",
    "    plt.yscale(\"log\")  # Execution times also often grow polynomially/exponentially\n",
    "    plt.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_nan_occurrences_by_input(\n",
    "    df: pd.DataFrame,\n",
    "    output_col: str,\n",
    "    input_col: str,\n",
    "    hardware_id: str,\n",
    "    top_n: int = 20,\n",
    "):\n",
    "    \"\"\"\n",
    "    Identifies and plots input shapes that most frequently have NaN values\n",
    "    in the specified output column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to analyze.\n",
    "        output_col (str): The name of the column to check for NaNs.\n",
    "        input_col (str): The column to analyze NaNs results based on.\n",
    "        hardware_id (str): Identifier for the current hardware (for title).\n",
    "        top_n (int): Number of top input shapes with NaNs to display.\n",
    "    \"\"\"\n",
    "    if output_col not in df.columns:\n",
    "        print(f\"Error: Output column '{output_col}' not found in DataFrame.\")\n",
    "        return\n",
    "    if input_col not in df.columns:\n",
    "        print(f\"Error: Input col '{input_col}' not found in DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # Filter rows where the output column is NaN\n",
    "    nan_df = df[df[output_col].isna()]\n",
    "\n",
    "    if nan_df.empty:\n",
    "        print(f\"No NaN values found in '{output_col}' for hardware '{hardware_id}'.\")\n",
    "        return\n",
    "\n",
    "    # Count NaN occurrences for each input_shape_id\n",
    "    nan_counts_by_shape = nan_df[input_col].value_counts().nlargest(top_n)\n",
    "\n",
    "    if nan_counts_by_shape.empty:\n",
    "        print(\n",
    "            f\"Found NaN values, but could not aggregate by '{input_col}'.\"\n",
    "        )  # Should not happen if nan_df is not empty\n",
    "        return\n",
    "\n",
    "    print(\n",
    "        f\"Top {min(top_n, len(nan_counts_by_shape))} input shapes with the most NaN values in '{output_col}':\"\n",
    "    )\n",
    "    print(nan_counts_by_shape)\n",
    "\n",
    "    plt.figure(\n",
    "        figsize=(12, max(6, len(nan_counts_by_shape) * 0.4))\n",
    "    )  # Adjust height based on number of bars\n",
    "    sns.barplot(x=nan_counts_by_shape.values, y=nan_counts_by_shape.index, orient=\"h\")\n",
    "    plt.title(\n",
    "        f\"Top {min(top_n, len(nan_counts_by_shape))} Input Shapes with Most NaN in '{output_col}'\\n(Hardware: {hardware_id})\"\n",
    "    )\n",
    "    plt.xlabel(f\"Number of NaN Occurrences in '{output_col}'\")\n",
    "    plt.ylabel(f\"{input_col}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not master_df.empty:\n",
    "    # --- Basic Exploration & Preparation ---\n",
    "    print(\"\\n--- Unique Hyperparameter Sets ---\")\n",
    "    print(master_df[\"hyperparameter_set\"].unique())\n",
    "\n",
    "    # Create a unique identifier for each input shape for easier grouping\n",
    "    master_df[\"input_shape_id\"] = master_df[INPUT_COLS].apply(\n",
    "        lambda row: \"_\".join(row.astype(str)), axis=1\n",
    "    )\n",
    "\n",
    "    # Rename it1 column\n",
    "    master_df.rename(columns={OUTPUT_COL: \"execution_time\"}, inplace=True)\n",
    "\n",
    "    # Add a new column for gflops\n",
    "    macs = 2.0 * master_df[\"M\"] * master_df[\"K\"] * master_df[\"N\"]\n",
    "    gflops = macs / (master_df[\"execution_time\"] * 1000)\n",
    "    master_df[\"gflops\"] = gflops\n",
    "\n",
    "    # Add a new column for normalized execution time (by gflops)\n",
    "    master_df[\"mac_normalized_execution_time\"] = master_df[\"execution_time\"] / macs\n",
    "\n",
    "    # Add a new column for matrix size\n",
    "    master_df[\"MxKxN\"] = master_df[\"M\"] * master_df[\"K\"] * master_df[\"N\"]\n",
    "\n",
    "    print(\"\\n--- Edited Data Head ---\")\n",
    "    print(master_df.head())\n",
    "\n",
    "    # --- Visualizations ---\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    # Filter the dataframe for some specific variable (for example, compiler)\n",
    "    df_analysis = master_df[master_df[\"hardware_id\"] == \"strix\"].copy()\n",
    "    df_analysis = master_df.copy()\n",
    "\n",
    "    if df_analysis.empty:\n",
    "        print(f\"No data to analyze for current dataframe.\")\n",
    "    else:\n",
    "        # Compare performance for a *specific* input shape (Bar Plot), possible to select a given shape\n",
    "        # hyperparameter_comparison_for_sampled_column(\n",
    "        #     df_analysis[df_analysis[\"compiler\"] == \"peano\"], \"execution_time\", hardware, sampled_column=\"input_shape_id\"\n",
    "        # )\n",
    "\n",
    "        # Overall performance distribution (Box Plot)\n",
    "        # print(\"\\n--- Overall Performance Distribution by Hyperparameter Set ---\")\n",
    "        # distribution_analysis_box_plot(df_analysis, \"execution_time\", hardware)\n",
    "\n",
    "        # print(\"\\n--- Overall Mac Normalized Above Matrix Size of 10e9 Performance Distribution by Hyperparameter Set ---\")\n",
    "        # distribution_analysis_box_plot(df_analysis[df_analysis[\"MxKxN\"] > 10e9], \"mac_normalized_execution_time\", hardware)\n",
    "        \n",
    "        # print(\"\\n--- Overall Mac Normalized Execution Time Distribution by Hyperparameter Set ---\")\n",
    "        # distribution_analysis_box_plot(df_analysis, \"gflops\", hardware)\n",
    "\n",
    "        # Identify best hyperparameter set for each input shape and count number of wins\n",
    "        # winner_on_grouped_column(\n",
    "        #     df_analysis,\n",
    "        #     \"input_shape_id\",\n",
    "        #     \"execution_time\",\n",
    "        #     hardware,\n",
    "        #     grouped_column=\"input_shape_id\",\n",
    "        # )\n",
    "\n",
    "        # Average Performance Rank (More advanced)\n",
    "        # For each input_shape, rank hyperparameter sets by their execution time.\n",
    "        # Then average these ranks for each hyperparameter set. Lower average rank is better.\n",
    "        print(\"\\n--- Average Performance Rank (Lower is Better) ---\")\n",
    "\n",
    "        average_performance_rank(\n",
    "            df_analysis, \"execution_time\", hardware, grouped_column=\"input_shape_id\"\n",
    "        )\n",
    "\n",
    "        temp = df_analysis[df_analysis[\"compiler\"] == \"chess\"]\n",
    "        average_performance_rank(\n",
    "            temp[temp[\"rst\"] != \"8x8x8\"], \"execution_time\", hardware, grouped_column=\"input_shape_id\"\n",
    "        )\n",
    "\n",
    "        average_performance_rank(\n",
    "            temp[temp[\"rst\"] == \"8x8x8\"], \"execution_time\", hardware, grouped_column=\"input_shape_id\"\n",
    "        )\n",
    "\n",
    "        # Scatter plots: Input vs. Output, colored by hyperparameter set\n",
    "        # print(f\"\\n--- Matrix Size vs Execution Time by Hyperparameter Set ---\")\n",
    "        # classic_line_plot(df_analysis, \"MxKxN\", \"execution_time\", hardware)\n",
    "\n",
    "        # 3D Scatter Plot (Plotly Express)\n",
    "        # print(\"\\n--- 3D Scatter Plot: Inputs vs. Output (Plotly) ---\")\n",
    "        # scatter_plot_3d(\n",
    "        #     df_analysis,\n",
    "        #     \"MxKxN\",\n",
    "        #     \"compiler\",\n",
    "        #     \"execution_time\",\n",
    "        #     hardware,\n",
    "        # )\n",
    "\n",
    "        print(\n",
    "            f\"\\n--- Gflops vs. matrix size (Hardware: {hardware}) ---\"\n",
    "        )\n",
    "        plot_execution_time_vs_MxKxN(\n",
    "            df_analysis,\n",
    "            \"gflops\",\n",
    "            hardware,\n",
    "            MxKxN_col_name=\"MxKxN\",\n",
    "            hyperparam_set_col=\"hyperparameter_set\",\n",
    "        )\n",
    "\n",
    "        # print(\n",
    "        #     f\"\\n--- Gflops With Emulation vs. matrix size and only Peano (Hardware: {hardware}) ---\"\n",
    "        # )\n",
    "        # temp = df_analysis[df_analysis[\"rst\"] == \"8x8x8\"]\n",
    "        # plot_execution_time_vs_MxKxN(\n",
    "        #     temp[temp[\"compiler\"] == \"peano\"],\n",
    "        #     \"gflops\",\n",
    "        #     hardware,\n",
    "        #     MxKxN_col_name=\"MxKxN\",\n",
    "        #     hyperparam_set_col=\"hyperparameter_set\",\n",
    "        # )\n",
    "\n",
    "        # print(f\"Max value\")\n",
    "        # print(temp[temp[\"compiler\"] == \"peano\"][\"gflops\"].max())\n",
    "\n",
    "        # print(\n",
    "        #     f\"\\n--- Gflops Without Emulation vs. matrix size and only on Peano (Hardware: {hardware}) ---\"\n",
    "        # )\n",
    "        # temp = df_analysis[df_analysis[\"rst\"] != \"8x8x8\"]\n",
    "        # plot_execution_time_vs_MxKxN(\n",
    "        #     temp[temp[\"compiler\"] == \"peano\"],\n",
    "        #     \"gflops\",\n",
    "        #     hardware,\n",
    "        #     MxKxN_col_name=\"MxKxN\",\n",
    "        #     hyperparam_set_col=\"hyperparameter_set\",\n",
    "        # )\n",
    "\n",
    "        print(\n",
    "            f\"\\n--- Gflops vs. matrix size and only on Chess and 4 cols (Hardware: {hardware}) ---\"\n",
    "        )\n",
    "        temp = df_analysis[df_analysis[\"cols\"] == \"4\"]\n",
    "        plot_execution_time_vs_MxKxN(\n",
    "            temp[temp[\"compiler\"] == \"chess\"],\n",
    "            \"gflops\",\n",
    "            hardware,\n",
    "            MxKxN_col_name=\"MxKxN\",\n",
    "            hyperparam_set_col=\"hyperparameter_set\",\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"\\n--- Gflops vs. matrix size and only on Chess and 8 cols (Hardware: {hardware}) ---\"\n",
    "        )\n",
    "        temp = df_analysis[df_analysis[\"cols\"] == \"8\"]\n",
    "        plot_execution_time_vs_MxKxN(\n",
    "            temp[temp[\"compiler\"] == \"chess\"],\n",
    "            \"gflops\",\n",
    "            hardware,\n",
    "            MxKxN_col_name=\"MxKxN\",\n",
    "            hyperparam_set_col=\"hyperparameter_set\",\n",
    "        )\n",
    "\n",
    "        # # Create a hyperparameter set without the compiler for this comparison\n",
    "        # df_analysis[\"hyperparameter_set_compiler_comparison\"] = df_analysis.apply(\n",
    "        #     lambda row: \"_\".join(\n",
    "        #         [\n",
    "        #             row[\"mkn\"],\n",
    "        #             row[\"rst\"],\n",
    "        #             row[\"out\"],\n",
    "        #             row[\"cols\"],\n",
    "        #         ]\n",
    "        #     ),\n",
    "        #     axis=1,\n",
    "        # )\n",
    "\n",
    "        # print(\n",
    "        #     f\"\\n--- Compiler Comparison for Identical Base Configurations (Hardware: {hardware}) ---\"\n",
    "        # )\n",
    "\n",
    "        # compare_compilers_for_identical_configs(\n",
    "        #     df_analysis,\n",
    "        #     \"execution_time\",\n",
    "        #     hardware,\n",
    "        #     compiler_col=\"compiler\",\n",
    "        #     base_config_col=\"hyperparameter_set_compiler_comparison\",\n",
    "        #     shape_id_col=\"input_shape_id\",\n",
    "        # )\n",
    "\n",
    "        # print(\n",
    "        #     f\"\\n--- Compiler Comparison for Identical Base Configurations (Only emulation) (Hardware: {hardware}) ---\"\n",
    "        # )\n",
    "\n",
    "        # compare_compilers_for_identical_configs(\n",
    "        #     df_analysis[df_analysis[\"rst\"] == \"8x8x8\"],\n",
    "        #     \"execution_time\",\n",
    "        #     hardware,\n",
    "        #     compiler_col=\"compiler\",\n",
    "        #     base_config_col=\"hyperparameter_set_compiler_comparison\",\n",
    "        #     shape_id_col=\"input_shape_id\",\n",
    "        # )\n",
    "\n",
    "        # print(\n",
    "        #     f\"\\n--- Compiler Comparison for Identical Base Configurations Without Emulation (Hardware: {hardware}) ---\"\n",
    "        # )\n",
    "\n",
    "        # compare_compilers_for_identical_configs(\n",
    "        #     df_analysis[df_analysis[\"rst\"] != \"8x8x8\"],\n",
    "        #     \"execution_time\",\n",
    "        #     hardware,\n",
    "        #     compiler_col=\"compiler\",\n",
    "        #     base_config_col=\"hyperparameter_set_compiler_comparison\",\n",
    "        #     shape_id_col=\"input_shape_id\",\n",
    "        # )\n",
    "\n",
    "        # print(f\"\\n--- Execution Time vs. matrix size (Hardware: {hardware}) ---\")\n",
    "        # plot_execution_time_vs_MxKxN(\n",
    "        #     df_analysis,\n",
    "        #     \"execution_time\",\n",
    "        #     hardware,\n",
    "        #     MxKxN_col_name=\"MxKxN\",\n",
    "        #     hyperparam_set_col=\"hyperparameter_set\",\n",
    "        # )\n",
    "\n",
    "        # print(f\"\\n--- NaN Occurrences by Input Shape (Hardware: {hardware}) ---\")\n",
    "        # master_df_nans[\"input_shape_id\"] = master_df_nans[INPUT_COLS].apply(\n",
    "        #     lambda row: \"_\".join(row.astype(str)), axis=1\n",
    "        # )\n",
    "        # plot_nan_occurrences_by_input(\n",
    "        #     master_df_nans,\n",
    "        #     output_col=\"It1\",\n",
    "        #     input_col=\"input_shape_id\",\n",
    "        #     hardware_id=hardware,\n",
    "        #     top_n=20,\n",
    "        # )\n",
    "\n",
    "        # print(f\"\\n--- NaN Occurrences by Input Cols (Hardware: {hardware}) ---\")\n",
    "        # plot_nan_occurrences_by_input(\n",
    "        #     master_df_nans,\n",
    "        #     output_col=\"It1\",\n",
    "        #     input_col=\"cols\",\n",
    "        #     hardware_id=hardware,\n",
    "        #     top_n=20,\n",
    "        # )\n",
    "\n",
    "        # print(f\"\\n--- NaN Occurrences by Input Cols (only 8 cols) (Hardware: {hardware}) ---\")\n",
    "        # plot_nan_occurrences_by_input(\n",
    "        #     master_df_nans[master_df_nans[\"cols\"] == \"8\"],\n",
    "        #     output_col=\"It1\",\n",
    "        #     input_col=\"input_shape_id\",\n",
    "        #     hardware_id=hardware,\n",
    "        #     top_n=20,\n",
    "        # )\n",
    "\n",
    "        \n",
    "\n",
    "else:\n",
    "    print(\"Master DataFrame is empty. No analysis performed.\")\n",
    "\n",
    "print(\"\\n--- Visualization end ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_bar(\n",
    "    df, \n",
    "    x_col, \n",
    "    y_cols, \n",
    "    title=None, \n",
    "    xlabel=None, \n",
    "    ylabel=None, \n",
    "    figsize=(12, 8)\n",
    "):\n",
    "    \"\"\"\n",
    "    Groups data by the x_col, computes the average of y_cols, and \n",
    "    displays the result as a stacked bar plot with simplified x-axis labels.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        x_col (str): The column name to group by and use for the x-axis.\n",
    "        y_cols (list of str): A list of column names to be averaged and stacked.\n",
    "        title (str, optional): The title of the plot. Defaults to a generated title.\n",
    "        xlabel (str, optional): The label for the x-axis. Defaults to \"Problem Size\".\n",
    "        ylabel (str, optional): The label for the y-axis. Defaults to \"Average Value\".\n",
    "        figsize (tuple, optional): The size of the figure. Defaults to (12, 8).\n",
    "    \"\"\"\n",
    "    # 1. Group by the x-column and calculate the mean of the y-columns.\n",
    "    # .reset_index() converts the grouped output back into a DataFrame.\n",
    "    agg_df = df.groupby(x_col)[y_cols].mean().reset_index()\n",
    "    \n",
    "    # Optional: Sort values to have a logical progression on the x-axis\n",
    "    # This assumes the size can be extracted and converted to an integer for sorting.\n",
    "    try:\n",
    "        agg_df['sort_key'] = agg_df[x_col]\n",
    "        agg_df = agg_df.sort_values('sort_key').drop('sort_key', axis=1)\n",
    "    except (ValueError, IndexError):\n",
    "        # If the label format is not as expected, sort alphabetically\n",
    "        agg_df = agg_df.sort_values(x_col)\n",
    "\n",
    "    # 2. Set the x-column as the index for plotting.\n",
    "    plot_df = agg_df.set_index(x_col)\n",
    "\n",
    "    # 3. Create the stacked bar plot.\n",
    "    ax = plot_df[y_cols].plot(\n",
    "        kind='bar',\n",
    "        stacked=True,\n",
    "        figsize=figsize,\n",
    "        width=0.8,\n",
    "        edgecolor='black'\n",
    "    )\n",
    "\n",
    "    # --- Formatting and Customization ---\n",
    "    \n",
    "    # 4. Set title and labels. Default labels are now more descriptive.\n",
    "    plt.title(title or f\"Average {', '.join(y_cols)} by {x_col}\", fontsize=16, pad=20)\n",
    "    plt.xlabel(xlabel or \"Problem Size\", fontsize=12)\n",
    "    plt.ylabel(ylabel or \"Average Value\", fontsize=12)\n",
    "\n",
    "    # 6. Rotate x-axis labels for better readability.\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "\n",
    "    # 7. Add a grid for easier value reading.\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # 8. Improve legend placement.\n",
    "    plt.legend(title=\"Metrics\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # 9. Ensure everything fits nicely.\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 10. Display the plot.\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n--- Shuffle time estimation ---\")\n",
    "df_shuffle = df_analysis[\n",
    "    ((df_analysis[\"compiler\"] == \"chess\") & (df_analysis[\"hyperparameter_set\"] == \"64x64x64_8x8x8_bfp16_8_chess\"))\n",
    "].dropna(subset=\"shuffle_time\").copy()\n",
    "print(df_shuffle)\n",
    "# plot_execution_time_vs_MxKxN(df_shuffle, \"shuffle_time\", hardware, MxKxN_col_name=\"MxKxN\", hyperparam_set_col=\"hyperparameter_set\")\n",
    "plot_stacked_bar(\n",
    "    df_shuffle,\n",
    "    \"MxKxN\",\n",
    "    [\"execution_time\", \"shuffle_time\"],\n",
    "    title=\"Total execution time including CPU shuffle time\",\n",
    "    xlabel=\"MxKxN\",\n",
    "    ylabel=\"Average Time (us)\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
